{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNptn1UKbgd2oowA9B6kez7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejuuu-7774/GENAI_collabs/blob/main/RNN_to_Transformers_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers Example"
      ],
      "metadata": {
        "id": "DQmATexj5esQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q transformers datasets accelerate\n",
        "\n",
        "# from transformers import AutoTokenizer , AutoModelForSequenceClassification , Trainer , TrainingArguments\n",
        "# from datasets import Dataset"
      ],
      "metadata": {
        "id": "5wpHJIY15oZu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Lxb0RXyZ47sB"
      },
      "outputs": [],
      "source": [
        "# data = {\n",
        "#     \"text\": [\n",
        "#         \"I am so happy today\",\n",
        "#         \"This is the best day\",\n",
        "#         \"I feel terrible and sad\",\n",
        "#         \"This is a disaster\",\n",
        "#         \"I am feeling great\",       # Added 'great'\n",
        "#         \"What a wonderful morning\", # Added 'wonderful'\n",
        "#         \"I hate this movie\",        # Added 'hate'\n",
        "#         \"This is awful\",            # Added 'awful'\n",
        "#         \"I love this place\",        # Added 'love'\n",
        "#         \"I am depressed\"            # Added 'depressed'\n",
        "#     ],\n",
        "#     \"label\": [1, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n",
        "# }\n",
        "# dataset = Dataset.from_dict(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = \"distilbert-base-uncased\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "id": "2GKDI4rw5nqK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def tokenize_function(examples):\n",
        "#     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=16)"
      ],
      "metadata": {
        "id": "-LoZZrSH5nnb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer_dataset = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "AVLdzESX5nk6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# args = TrainingArguments(\n",
        "#     output_dir=\"simple_model_v2\",\n",
        "#     num_train_epochs=15,\n",
        "#     per_device_train_batch_size=4,\n",
        "#     report_to=\"none\"\n",
        "# )"
      ],
      "metadata": {
        "id": "BoC9mt3W7-Z9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=args,\n",
        "#     train_dataset=tokenizer_dataset\n",
        "# )"
      ],
      "metadata": {
        "id": "bPi6wFy59M44"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.train()"
      ],
      "metadata": {
        "id": "M_mXSeuP-NOX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_sentences = [\"I am feeling great!\" , \"This is the worst day ever.\"]\n",
        "# for text in test_sentences:\n",
        "#     inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "#     logits = model(**inputs).logits\n",
        "#     prediction = logits.argmax().item()\n",
        "#     label = \"Happy\" if prediction == 1 else \"Sad\"\n",
        "#     print(f\"Input: '{text}' -> Prediction: {label}\")"
      ],
      "metadata": {
        "id": "-OQzfSHZ-PuQ"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}